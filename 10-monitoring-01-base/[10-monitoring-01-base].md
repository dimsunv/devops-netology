# Домашнее задание к занятию "10.01. Зачем и что нужно мониторить"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

- мониторинг операционной системы:
  - процессор:
    - cpu usage
    - load average
  - память:
    - free
    - swap
  - диск:
    - объем данных
    - скорость записи/чтения
    - количество inodes
  - сеть:
    - загруженность интерфейсов
- мониторинг сервисов (субд, веб-серверов, файловые хранилища):
  - доступность
  - загруженность
  - наличие ошибок
  - время отклика
- мониторинг приложения:
  - HTTP-запросы:
    - общее количество запросов
    - количество ошибочных запросов
    - время выполнения запросов
  - операции расчета и вывода данных:
    - количество операций
    - статус операций
    - время исполнения операций

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал,
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы
можете ему предложить?

- RAM/inodes/CPUla:
  - память
  - диск
  - нагрузка процессора

- Нужно исходить из выставленного ТЗ на мониторинг системы. Поэтому, либо приводить мониторинг к ТЗ, либо обойтись минимальным набором без особой нагрузки на бюджет:
  * доступность системы в процентах;
  * время выполнения запрошенной клиентом операции (минимальное, среднее и максимальное)
  * допустимый процент ошибок


3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации,
чтобы разработчики получали ошибки приложения?

В таком случае работы по обработке ошибок лягут на плечи разработчиков. Это или переделка приложения под Sentry, или формирование текстовых логов с кодами ошибок.
- Можно предложить построить бюджетную схему сбора логов. Например,
    - собирать только ERROR
    - формировать текстовые логи на общей шаре
    - минимальный логротейт
    - алерты только на критические ошибки

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов.
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Нужно собрать информацию обо всех имеющихся в логах кодах ответов.
Скорее всего присутствую коды 100-199 или 300-399, которые не являются ошибочными. Возможно стоит рассмотреть функцию персентиль по коду 200.

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`.
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)

     ...

  + metric_N (метрика N)

- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.


<details>
<summary>metrics.py</summary>

```python
#!/usr/bin/python3

from datetime import datetime
import json

with open(f"/proc/loadavg", "r") as f:
  loadavg = f.read().split('\n')
  loadavg = loadavg[0].split()

with open(f"/proc/meminfo", "r") as f:
  mem = f.read().split('\n')
  memtotal = mem[0].split()
  memfree = mem[1].split()

with open(f"/proc/swaps", "r") as f:
  swap = f.read().split('\n')
  swap = swap[1].split()

with open(f"/proc/uptime", "r") as f:
  uptime = f.read().split()

log = {
    "date": datetime.now().strftime('%Y-%m-%d %H.%M.%S'),
    "load average": {
        "1m": loadavg[0],
        "5m": loadavg[1],
        "15m": loadavg[2]
    },
    "memory": {
        "total": memtotal[1],
        "free": memfree[1]
    },
    "swap": {
        "size": swap[2],
        "used": swap[3]
    },
    "uptime": uptime[0]
}

print(log)
```

</details>
---

* crontab -e

```
*/1 * * * * python3 /root/metrics.py 1>> /var/log/metrics.log 2>> /var/log/metrics_error.log
```
---

* /etc/logrotate.d/metrics.conf
```
/var/log/metrics.log
/var/log/metrics_error.log
{
	rotate 7
	daily
	missingok
	notifempty
	delaycompress
	compress
}
```
---

* metrics.log

```
{'date': '2022-11-15 14.22.01', 'load average': {'1m': '0.09', '5m': '0.13', '15m': '0.19'}, 'memory': {'total': '3983180', 'free': '179556'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365248.75'}
{'date': '2022-11-15 14.23.01', 'load average': {'1m': '0.16', '5m': '0.14', '15m': '0.18'}, 'memory': {'total': '3983180', 'free': '179052'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365308.83'}
{'date': '2022-11-15 14.24.01', 'load average': {'1m': '0.12', '5m': '0.13', '15m': '0.18'}, 'memory': {'total': '3983180', 'free': '179052'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365368.89'}
{'date': '2022-11-15 14.25.01', 'load average': {'1m': '0.04', '5m': '0.11', '15m': '0.17'}, 'memory': {'total': '3983180', 'free': '179052'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365428.97'}
{'date': '2022-11-15 14.26.01', 'load average': {'1m': '0.01', '5m': '0.08', '15m': '0.15'}, 'memory': {'total': '3983180', 'free': '179052'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365489.06'}
{'date': '2022-11-15 14.27.01', 'load average': {'1m': '0.04', '5m': '0.08', '15m': '0.15'}, 'memory': {'total': '3983180', 'free': '179052'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365549.14'}
{'date': '2022-11-15 14.28.01', 'load average': {'1m': '0.08', '5m': '0.09', '15m': '0.15'}, 'memory': {'total': '3983180', 'free': '179052'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365609.21'}
{'date': '2022-11-15 14.29.01', 'load average': {'1m': '0.06', '5m': '0.09', '15m': '0.14'}, 'memory': {'total': '3983180', 'free': '186940'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365669.29'}
{'date': '2022-11-15 14.30.01', 'load average': {'1m': '0.31', '5m': '0.15', '15m': '0.16'}, 'memory': {'total': '3983180', 'free': '172216'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365729.38'}
{'date': '2022-11-15 14.31.01', 'load average': {'1m': '0.42', '5m': '0.21', '15m': '0.18'}, 'memory': {'total': '3983180', 'free': '196472'}, 'swap': {'size': '2097148', 'used': '443964'}, 'uptime': '365789.46'}
```
